{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respected-principle",
   "metadata": {},
   "source": [
    "# Step 1 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-postage",
   "metadata": {},
   "source": [
    "# Excel Manage\n",
    "# 5/7/2021\n",
    "# Search, Sort and Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-virgin",
   "metadata": {},
   "source": [
    "### https://www.freecodecamp.org/news/how-to-create-read-update-and-search-through-excel-files-using-python-c70680d811d4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name and Path\n",
    "\n",
    "file_name = 'Mixture_major_2563_assembled_to_AI'\n",
    "# file_name = 'Mixture_major 2562_assembled_to_AI.xlsx'\n",
    "\n",
    "path_adress = \".\\\\งานวิจัย_นิติวิทยาศาสตร์\\\\DNA_Data\\\\\"\n",
    "dataset_path = path_adress + file_name + '.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file Name and Path\n",
    "\n",
    "file_name_save = 'New_Mixure_major_2563'\n",
    "# file_name_save = 'New_Mixure_major_2562_05102021.xlsx'\n",
    "\n",
    "path_adress_save = \".\\\\งานวิจัย_นิติวิทยาศาสตร์\\\\DNA_Data\\\\\"\n",
    "dataset_path_save = path_adress_save + file_name_save + '.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Major Marker\n",
    "columns_major_marker = ['Sample_Name', 'Marker']\n",
    "\n",
    "## Input\n",
    "columns_input = ['Allele_1', 'Allele_2', 'Allele_3', 'Allele_4',\n",
    "                 'Allele_5', 'Allele_6', 'Allele_7', 'Allele_8',\n",
    "                 'Height_1', 'Height_2', 'Height_3', 'Height_4',\n",
    "                 'Height_5', 'Height_6', 'Height_7', 'Height_8']\n",
    "## Output\n",
    "columns_output_major_marker = ['Out_Name', 'Out_Mark']\n",
    "columns_output = ['Out_1', 'Out_2']\n",
    "\n",
    "# print(len(columns_input))\n",
    "# print(len(columns_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header_name = columns_major_marker + columns_input + columns_output_major_marker + columns_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "theFile = openpyxl.load_workbook(dataset_path)\n",
    "allSheetNames = theFile.sheetnames\n",
    "\n",
    "print(\"All sheet names {} \" .format(theFile.sheetnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theFile.sheetnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read All Mixure Major\n",
    "header_name = columns_major_marker + columns_input\n",
    "sheet_n = theFile.sheetnames[0]\n",
    "\n",
    "cols = 'a:r'\n",
    "df_in = pd.read_excel(dataset_path, sheet_name=sheet_n, header=None,\n",
    "                       skiprows=[0,1], usecols=cols, names=header_name)\n",
    "# df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Output Major Full 39\n",
    "header_name = columns_output_major_marker + columns_output\n",
    "sheet_n = theFile.sheetnames[1]\n",
    "\n",
    "cols = 'a:d'\n",
    "df_Full = pd.read_excel(dataset_path, sheet_name=sheet_n, header=None,\n",
    "                          skiprows=[0,1], usecols=cols, names=header_name)\n",
    "# df_Full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Output Major Partial 103\n",
    "header_name = columns_output_major_marker + columns_output\n",
    "sheet_n = theFile.sheetnames[2]\n",
    "\n",
    "cols = 'a:d'\n",
    "df_Partial = pd.read_excel(dataset_path, sheet_name=sheet_n, header=None,\n",
    "                       skiprows=[0,1], usecols=cols, names=header_name)\n",
    "# df_Partial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For loop\n",
    "\n",
    "currentSheet = theFile[theFile.sheetnames[0]]\n",
    "# print(currentSheet['B4'].value)\n",
    "\n",
    "# Mix_profile = 142\n",
    "txt = theFile.sheetnames[0]\n",
    "Mix_profile = int(txt[txt.find(\"=\")+1:])\n",
    "\n",
    "for count in range(0,Mix_profile):\n",
    "    # count = 1\n",
    "    row_in = 3 + (count*25) \n",
    "    cell_name = \"{}{}\".format(\"A\", row_in)\n",
    "    prof_name = currentSheet[cell_name].value\n",
    "    print(\"cell position {} has value {}\".format(cell_name, prof_name))\n",
    "    # print(Name_Dstn)\n",
    "\n",
    "##---------------------------------------------------------------------------------##    \n",
    "    # Vale = prof_name\n",
    "    sheet_A = theFile[theFile.sheetnames[1]]\n",
    "    sheet_B = theFile[theFile.sheetnames[2]]\n",
    "    row = 0\n",
    "    Sheet_status = ' '\n",
    "    \n",
    "    for row_A in range(1, sheet_A.max_row + 1):\n",
    "        cell_name = \"{}{}\".format(\"A\", row_A)\n",
    "        if sheet_A[cell_name].value == prof_name:\n",
    "            print(\"The value {} in sheet names {} and cell position {} \"\n",
    "                      .format(sheet_A[cell_name].value, sheet_A , cell_name))\n",
    "            Sheet_status = 'Full'\n",
    "            break    \n",
    "    for row_B in range(1, sheet_B.max_row + 1):\n",
    "        cell_name = \"{}{}\".format(\"A\", row_B)\n",
    "        if sheet_B[cell_name].value == prof_name:\n",
    "            print(\"The value {} in sheet names {} and cell position {} \"\n",
    "                      .format(sheet_B[cell_name].value, sheet_B , cell_name))\n",
    "            Sheet_status = 'Partial'\n",
    "            break\n",
    "\n",
    "##---------------------------------------------------------------------------------##\n",
    "    if Sheet_status == 'Full' :\n",
    "        df_raw = df_Full[row_A-3 : (row_A-3)+25]\n",
    "        if count == 0:\n",
    "            df_out = df_raw\n",
    "            print('zero')\n",
    "        else:\n",
    "            df_out = df_out.append(df_raw, ignore_index = True)\n",
    "        print(\"**Major Full**\")\n",
    "        \n",
    "    elif Sheet_status == 'Partial' :\n",
    "        df_raw = df_Partial[row_B-3 : (row_B-3)+25]\n",
    "        if count == 0:\n",
    "            df_out = df_raw\n",
    "            print('zero')\n",
    "        else:\n",
    "            df_out = df_out.append(df_raw, ignore_index = True)\n",
    "        print(\"**Major Partial**\")\n",
    "    else :\n",
    "        print(\"**********Something Error**********\")\n",
    "    \n",
    "    # print(\"Sheet Statut :\",Sheet_status)\n",
    "    # df_out\n",
    "\n",
    "##---------------------------------------------------------------------------------##\n",
    "#    if count == 0:\n",
    "#        df_out = df_raw\n",
    "#        print('zero')\n",
    "#    else :\n",
    "#        df_out = df_out.append(df_raw, ignore_index = True)\n",
    "#        print('not zero')\n",
    "        \n",
    "    print(\"Count :\",count)\n",
    "    #df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_wonm = df_out[columns_output]\n",
    "# df_out_new\n",
    "print(len(df_out_wonm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "writer = pd.ExcelWriter(dataset_path_save)\n",
    "df_in.to_excel(writer, 'Sheet1', index=False, startcol=0)\n",
    "df_out.to_excel(writer, 'Sheet1', index=False, startcol=18)\n",
    "df_in.to_excel(writer, 'Sheet2', index=False, startcol=0)\n",
    "df_out_wonm.to_excel(writer, 'Sheet2', index=False, startcol=18)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-arrival",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "marine-annotation",
   "metadata": {},
   "source": [
    "# Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # txt = \"Mixtured Profile=97\"\n",
    "# txt = theFile.sheetnames[0]\n",
    "# x = int(txt[txt.find(\"=\")+1:])\n",
    "# print(type(x))\n",
    "# print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currentSheet = theFile[theFile.sheetnames[0]]\n",
    "# # print(currentSheet['B4'].value)\n",
    "\n",
    "# count = 1\n",
    "# row = 3 + (count*25) \n",
    "# cell_name = \"{}{}\".format(\"A\", row)\n",
    "# Name_Dstn = currentSheet[cell_name].value\n",
    "# print(\"cell position {} has value {}\".format(cell_name, Name_Dstn))\n",
    "# # print(Name_Dstn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V_le = Name_Dstn\n",
    "# sheet_A = theFile[theFile.sheetnames[1]]\n",
    "# sheet_B = theFile[theFile.sheetnames[2]]\n",
    "\n",
    "# for row in range(1, sheet_A.max_row + 1):\n",
    "#     cell_name = \"{}{}\".format(\"A\", row)\n",
    "#     if sheet_A[cell_name].value == V_le:\n",
    "#         print(\"The value {} in sheet names {} and cell position {} \"\n",
    "#                   .format(sheet_A[cell_name].value, sheet_A , cell_name))\n",
    "#         Sheet_status = 'Full'\n",
    "#         break    \n",
    "# for row in range(1, sheet_B.max_row + 1):\n",
    "#     cell_name = \"{}{}\".format(\"A\", row)\n",
    "#     if sheet_B[cell_name].value == V_le:\n",
    "#         print(\"The value {} in sheet names {} and cell position {} \"\n",
    "#                   .format(sheet_B[cell_name].value, sheet_B , cell_name))\n",
    "#         Sheet_status = 'Partial'\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-channel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# srt = row-3\n",
    "# stp = srt+25\n",
    "\n",
    "# if Sheet_status == 'Full' :\n",
    "#     df_out = df_out_Full[srt : stp]\n",
    "\n",
    "# elif Sheet_status == 'Partial' :\n",
    "#     df_out = df_out_Partial[srt : stp]\n",
    "\n",
    "# else:    \n",
    "#     print(\"Somthing Error\")\n",
    "    \n",
    "# print(\"Sheet Statut :\",Sheet_status)\n",
    "# # df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-canada",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if count == 0:\n",
    "#     df_raw = df_out\n",
    "#     print('zero')\n",
    "# else :\n",
    "#     df_raw = df_raw.append(df_out, ignore_index = True)\n",
    "#     print('not zero')\n",
    "# print(\"Count :\",count)\n",
    "# # df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-convergence",
   "metadata": {},
   "source": [
    "# Excel\n",
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'Excel_exam_1.xlsx'\n",
    "# theFile = openpyxl.load_workbook(file_name)\n",
    "# allSheetNames = theFile.sheetnames\n",
    "\n",
    "# print(\"All sheet names {} \" .format(theFile.sheetnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currentSheet = theFile['Sheet1']\n",
    "# print(currentSheet['B4'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# row = 2 + (count*25) \n",
    "# cell_name = \"{}{}\".format(\"A\", row)\n",
    "# Name_Dstn = currentSheet[cell_name].value\n",
    "# print(\"cell position {} has value {}\".format(cell_name, Name_Dstn))\n",
    "# #print(Name_Dstn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V_le = 456\n",
    "# sheet_A = theFile['Sheet1']\n",
    "# sheet_B = theFile['Sheet2']\n",
    "\n",
    "# for row in range(1, sheet_A.max_row + 1):\n",
    "#     cell_name = \"{}{}\".format(\"A\", row)\n",
    "#     if sheet_A[cell_name].value == V_le:\n",
    "#         print(\"The value {} in sheet names {} and cell position {} \"\n",
    "#                   .format(sheet_A[cell_name].value, sheet_A , cell_name))\n",
    "            \n",
    "# for row in range(1, sheet_B.max_row + 1):\n",
    "#     cell_name = \"{}{}\".format(\"A\", row)\n",
    "#     if sheet_B[cell_name].value == V_le:\n",
    "#         print(\"The value {} in sheet names {} and cell position {} \"\n",
    "#                   .format(sheet_B[cell_name].value, sheet_B , cell_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-heath",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eligible-variety",
   "metadata": {},
   "source": [
    "# Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-tucson",
   "metadata": {},
   "source": [
    "## Add rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Importing pandas as pd\n",
    "# import pandas as pd\n",
    "\n",
    "# # Creating the first Dataframe using dictionary\n",
    "# df1 = df = pd.DataFrame({\"a\":[1, 2, 3, 4],\n",
    "# \t\t\t\t\t\t\"b\":[5, 6, 7, 8]})\n",
    "\n",
    "# # Creating the Second Dataframe using dictionary\n",
    "# df2 = pd.DataFrame({\"a\":[1, 2, 3],\n",
    "# \t\t\t\t\t\"b\":[5, 6, 7]})\n",
    "\n",
    "# # Print df1\n",
    "# print(df1, \"\\n\")\n",
    "\n",
    "# # Print df2\n",
    "# df2\n",
    "\n",
    "# # to append df2 at the end of df1 dataframe\n",
    "# #df1.append(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## A continuous index value will be maintained\n",
    "# ## across the rows in the new appended data frame.\n",
    "# df1.append(df2, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-middle",
   "metadata": {},
   "source": [
    "## Add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## importing pandas library\n",
    "# import pandas as pd\n",
    "\n",
    "# ## creating and initializing a nested list\n",
    "# students = [['jackma', 34, 'Sydeny', 'Australia'],\n",
    "# \t\t\t['Ritika', 30, 'Delhi', 'India'],\n",
    "# \t\t\t['Vansh', 31, 'Delhi', 'India'],\n",
    "# \t\t\t['Nany', 32, 'Tokyo', 'Japan'],\n",
    "# \t\t\t['May', 16, 'New York', 'US'],\n",
    "# \t\t\t['Michael', 17, 'las vegas', 'US']]\n",
    "\n",
    "# ## Create a DataFrame object\n",
    "# df = pd.DataFrame(students,\n",
    "# \t\t\t\tcolumns=['Name', 'Age', 'City', 'Country'],\n",
    "# \t\t\t\tindex=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## creating columns 'Age' and 'ID' at\n",
    "# ## 2nd and 3rd position using\n",
    "# ## dataframe.insert() function\n",
    "# df.insert(4, \"Marks\", [90, 70, 45, 33, 88, 77], True)\n",
    "# df.insert(5, \"ID\", [101, 201, 401, 303, 202, 111], True)\n",
    "\n",
    "\n",
    "# ## Displaying the Data frame\n",
    "# df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNAandBone-Project-DNN",
   "language": "python",
   "name": "dbenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
